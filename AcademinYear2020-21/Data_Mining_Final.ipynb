{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Mining - Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY5QtRTAzr2B",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_rX77Bzc9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip data.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4bFEAkTzprq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFFDGrqbz3su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(\"data/train.csv\")\n",
        "df_test = pd.read_csv(\"data/impermium_verification_labels.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Kys4Pg4cyU",
        "colab_type": "text"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X6o4Pbv0-h_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def cleanup(series):\n",
        "    series = series.apply(lambda x: bytes(x, 'ascii').decode('unicode-escape'))\n",
        "    # remove utf-8 control charecters\n",
        "    series = series.str.replace(r\"\\\\x\\w\\w\", \" \")\n",
        "    # remove urls\n",
        "    series = series.str.replace(r\"https?://.*([\\s]|$)\", \" \")\n",
        "    # convert didn't to did not\n",
        "    series = series.str.replace(r\"(\\w+)n't\", r\"\\1 not\")\n",
        "    # remove weird charecters\n",
        "    series = series.str.replace(r\"(\\\\n|\\\\r)\", \" \")\n",
        "    series = series.str.replace(r\"[\\./@\\\"'\\\\!@#$%^&*()\\-_=+{\\[\\]}?/>,<;:|`~]\", \" \")\n",
        "    # remove digits\n",
        "    series = series.str.replace(r\"\\d\", \"\")\n",
        "    # remove single letters\n",
        "    # series = series.str.replace(r\"(\\s|^)\\d(\\s|$)\", \" \")\n",
        "    # trim spaces\n",
        "    series = series.str.replace(\"\\s+\", \" \")\n",
        "    # convert to lowercase\n",
        "    series = series.str.lower()\n",
        "\n",
        "    return series"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37WIxObhLllh",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization and Stop Word removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sftwTUnLLgMk",
        "colab_type": "code",
        "outputId": "97400ea4-d2fc-4f65-911e-631054d0357d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "stopwords_set = {x for x in stopwords.words()}\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return \" \".join([\n",
        "        lemmatizer.lemmatize(w)\n",
        "        for w in w_tokenizer.tokenize(text) \n",
        "        if w not in stopwords_set\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3yMoaF-OEk9",
        "colab_type": "text"
      },
      "source": [
        "## Parts of Speech\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDx-TSSEOG6a",
        "colab_type": "code",
        "outputId": "c45d9f05-fd30-45a7-d288-06b0d588729f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tag_list = []\n",
        "\n",
        "def parts_of_speech(series, fit=True):\n",
        "    global tag_list\n",
        "    def count_pos(text):\n",
        "        tokens = w_tokenizer.tokenize(text)\n",
        "        tags = nltk.pos_tag(tokens)\n",
        "        result = {}\n",
        "        for _, tag in tags:\n",
        "            if tag not in result:\n",
        "                result[tag]  = 0\n",
        "            result[tag] += 1\n",
        "        for tag in result:\n",
        "            result[tag] /= len(tokens)\n",
        "        return result\n",
        "    items = []\n",
        "    for _, value in series.iteritems():\n",
        "        items.append(count_pos(value))\n",
        "    \n",
        "    if fit:\n",
        "        df = pd.DataFrame(items).fillna(0)\n",
        "        tag_list = df.columns\n",
        "        return df\n",
        "    else:\n",
        "        return pd.DataFrame(items, columns=tag_list).fillna(0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHPIPLoxwarg",
        "colab_type": "text"
      },
      "source": [
        "## Classifier Evaluation\n",
        "\n",
        "User accuracy, recall and f1 score to measure accuracy of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8MSIZMpwZth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
        "\n",
        "def evaluate(classifier, y_true, y_pred):\n",
        "    y_acc_score = accuracy_score(df_test[\"Insult\"], y_pred)\n",
        "    y_recall_score = recall_score(df_test[\"Insult\"], y_pred)\n",
        "    y_f1_score = f1_score(df_test[\"Insult\"], y_pred)\n",
        "\n",
        "    print(f\"Accuracy : {y_acc_score:.4}\")\n",
        "    print(f\"Recall : {y_recall_score:.4}\")\n",
        "    print(f\"F1 Score : {y_f1_score:.4}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilo2hgu-zt8q",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzJwn_gO0liq",
        "colab_type": "code",
        "outputId": "c34ee031-d32b-4005-d299-5e26fb1376e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "def bayes_simple():\n",
        "    train_comments = cleanup(df_train[\"Comment\"])\n",
        "    test_comments= cleanup(df_test[\"Comment\"])\n",
        "\n",
        "    vectorizer = CountVectorizer(\n",
        "        lowercase=True,\n",
        "        strip_accents='unicode',\n",
        "        analyzer=\"word\",\n",
        "        min_df=0.02, max_df=0.7)\n",
        "    train_bow = vectorizer.fit_transform(train_comments).todense()\n",
        "    test_bow = vectorizer.transform(test_comments).todense()\n",
        "\n",
        "    classifier = GaussianNB(var_smoothing=0.01, priors=[0.8, 0.2])\n",
        "    classifier.fit(train_bow, df_train[\"Insult\"])\n",
        "    \n",
        "    y_pred = classifier.predict(test_bow)\n",
        "    evaluate(classifier, df_test[\"Insult\"], y_pred)\n",
        "\n",
        "bayes_simple()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.4779\n",
            "Recall : 0.9424\n",
            "F1 Score : 0.635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jSVHJwyFUvd",
        "colab_type": "code",
        "outputId": "e27260ea-f226-4901-a48e-a98130562d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "def bayes_lemmatize():\n",
        "    train_comments = cleanup(df_train[\"Comment\"]).apply(lemmatize_text)\n",
        "    test_comments= cleanup(df_test[\"Comment\"]).apply(lemmatize_text)\n",
        "\n",
        "    vectorizer = CountVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        ngram_range=(1, 1)) # replace with (2,2) for bigrams, however the score is worse\n",
        "\n",
        "    train_bow = vectorizer.fit_transform(train_comments).todense()\n",
        "    test_bow = vectorizer.transform(test_comments).todense()\n",
        "\n",
        "    classifier = MultinomialNB(alpha=1)\n",
        "    classifier.fit(train_bow, df_train[\"Insult\"])\n",
        "    \n",
        "    y_pred = classifier.predict(test_bow)\n",
        "    evaluate(classifier, df_test[\"Insult\"], y_pred)\n",
        "bayes_lemmatize()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.6814\n",
            "Recall : 0.4782\n",
            "F1 Score : 0.5913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZumMgIknnWoL",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDAf9gpvQZcr",
        "colab_type": "code",
        "outputId": "ca456264-f2cb-45f9-a267-776fa1746408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy import sparse\n",
        "\n",
        "def svm_data():\n",
        "    train_comments = cleanup(df_train[\"Comment\"]).apply(lemmatize_text)\n",
        "    test_comments= cleanup(df_test[\"Comment\"]).apply(lemmatize_text)\n",
        "\n",
        "    insult_vectorizer = TfidfVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        ngram_range=(1,2),\n",
        "        max_df=0.7,\n",
        "        min_df=0.002)\n",
        "    \n",
        "    df_train_insult = df_train[df_train[\"Insult\"] == 1]\n",
        "    train_insult_comments = cleanup(df_train_insult[\"Comment\"]).apply(lemmatize_text)\n",
        "    insult_vectorizer.fit(train_insult_comments)\n",
        "    \n",
        "\n",
        "    neutral_vectorizer = TfidfVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        ngram_range=(1,2),\n",
        "        max_df=0.7,\n",
        "        min_df=0.002)\n",
        "    \n",
        "    df_train_neutral = df_train[df_train[\"Insult\"] == 0]\n",
        "    train_neutral_comments = cleanup(df_train_neutral[\"Comment\"]).apply(lemmatize_text)\n",
        "\n",
        "    neutral_vectorizer.fit(train_neutral_comments)\n",
        "    \n",
        "    vectorizer = TfidfVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        max_df=0.2,\n",
        "        min_df=0.0008)\n",
        "    \n",
        "    train_bow = vectorizer.fit_transform(train_comments)\n",
        "    train_neubow = neutral_vectorizer.transform(train_comments)\n",
        "    train_inbow = insult_vectorizer.transform(train_comments)\n",
        "    train_pos = parts_of_speech(train_comments).values\n",
        "\n",
        "    test_bow = vectorizer.transform(test_comments)\n",
        "    test_neubow = neutral_vectorizer.transform(test_comments)\n",
        "    test_inbow = insult_vectorizer.transform(test_comments)\n",
        "    test_pos = parts_of_speech(test_comments, fit=False)\n",
        "\n",
        "    train_data = sparse.hstack([train_neubow, train_inbow, train_pos]).todense()\n",
        "    test_data = sparse.hstack([test_neubow, test_inbow, test_pos]).todense()\n",
        "    \n",
        "    print(train_bow.shape[-1], train_pos.shape[-1], train_neubow.shape[-1], train_inbow.shape[-1], train_data.shape[-1])\n",
        "\n",
        "    return train_data, test_data\n",
        "train_data, test_data = svm_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2601 32 1522 1058 2612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj9UQd7eLM_3",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XL34Db9LSL_",
        "colab_type": "code",
        "outputId": "86c08f00-feac-4a06-f692-3a81e3573ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "\n",
        "def run_svm():\n",
        "    classifier = SVC()\n",
        "    classifier.fit(train_data, df_train[\"Insult\"])\n",
        "\n",
        "    y_pred = classifier.predict(test_data)\n",
        "    evaluate(classifier, df_test[\"Insult\"], y_pred)\n",
        "\n",
        "run_svm()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.6595\n",
            "Recall : 0.3445\n",
            "F1 Score : 0.4937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_5GQVtxTdZE",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjqh1n2tTbAP",
        "colab_type": "code",
        "outputId": "a1964639-d8a5-41b8-8e00-3859b4e0ed3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def run_random_forest():\n",
        "    classifier = RandomForestClassifier(max_depth=150)\n",
        "    classifier.fit(train_data, df_train[\"Insult\"])\n",
        "\n",
        "    y_pred = classifier.predict(test_data)\n",
        "    evaluate(classifier, df_test[\"Insult\"], y_pred)\n",
        "\n",
        "run_random_forest()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.6837\n",
            "Recall : 0.4178\n",
            "F1 Score : 0.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9QaLR3ina3c",
        "colab_type": "text"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rILxoF-nZfO",
        "colab_type": "code",
        "outputId": "acf9a5d7-349c-498b-b430-987325273d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB\n",
        "from sklearn.svm import OneClassSVM, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "def run_opt():\n",
        "    # a_classifier = BernoulliNB()\n",
        "    # a_classifier.fit(train_data, df_train[\"Insult\"])\n",
        "\n",
        "    # b_classifier = RandomForestClassifier()\n",
        "    # b_classifier.fit(train_data, df_train[\"Insult\"])\n",
        "\n",
        "    # classifier = VotingClassifier(estimators=[('BernouliNB', a_classifier), ('RF', b_classifier)],\n",
        "    #                         voting='soft',\n",
        "    #                         weights=[4, 1])\n",
        "\n",
        "    classifier = BernoulliNB(alpha=0.8)\n",
        "    classifier.fit(train_data, df_train[\"Insult\"])\n",
        "\n",
        "    y_pred = classifier.predict(test_data)\n",
        "    evaluate(classifier, df_test[\"Insult\"], y_pred)\n",
        "\n",
        "\n",
        "\n",
        "run_opt()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7123\n",
            "Recall : 0.6555\n",
            "F1 Score : 0.6871\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}